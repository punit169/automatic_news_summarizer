{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sYg7fOJYOedm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth newspaper3k lxml[html_clean]\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip -q install streamlit beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define your model's path within Google Drive\n",
        "model_folder_path = '/content/drive/MyDrive/my_trained_model/my_trained_model' # Update with your model's path\n",
        "\n",
        "# 3. Check if the folder exists\n",
        "if os.path.exists(model_folder_path):\n",
        "  print(f\"Model folder found at: {model_folder_path}\")\n",
        "  # 4. List the contents of the folder (optional)\n",
        "  print(os.listdir(model_folder_path))\n",
        "else:\n",
        "  print(f\"Model folder not found at: {model_folder_path}\")\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "model, tokenizer = FastLanguageModel.from_pretrained( # Unpack the tuple into model and tokenizer\n",
        "    model_name=model_folder_path,  # Use the full path here\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "# 4. Set to evaluation mode - now on the model object\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH3wYie5OhdS",
        "outputId": "61712d5b-ad9d-4ed6-92b9-a78b52812efd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model folder found at: /content/drive/MyDrive/my_trained_model/my_trained_model\n",
            "['special_tokens_map.json', 'tokenizer.json', 'adapter_config.json', 'tokenizer_config.json', 'README.md', 'adapter_model.safetensors']\n",
            "==((====))==  Unsloth 2025.5.6: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 3072, padding_idx=128004)\n",
              "        (layers): ModuleList(\n",
              "          (0): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "          )\n",
              "          (1): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "          )\n",
              "          (2-27): 26 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#testing"
      ],
      "metadata": {
        "id": "_K4Sdc84O4yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "# if False:\n",
        "#     from unsloth import FastLanguageModel\n",
        "#     model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#         model_name = \"lora_model\",\n",
        "#         max_seq_length = max_seq_length,\n",
        "#         dtype = dtype,\n",
        "#         load_in_4bit = load_in_4bit,\n",
        "#     )\n",
        "#     FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# model = FastLanguageModel.from_pretrained('/content/drive/MyDrive/my_trained_model/my_trained_model')\n",
        "\n",
        "# max_seq_length = 2048\n",
        "# dtype = None\n",
        "# load_in_4bit = True\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name = \"/content/drive/MyDrive/my_trained_model/my_trained_model\",\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     dtype = dtype,\n",
        "#     load_in_4bit = load_in_4bit,\n",
        "# )\n",
        "FastLanguageModel.for_inference(model)\n",
        "text_content=\"\"\"\n",
        "Responding to geopolitical challenges\n",
        "He then went on to frame the challenging times in geopolitics. “We meet at a difficult time in world affairs. Two major conflicts are underway, each with its own global repercussions. The Covid pandemic has left many in the developing world deeply devastated. Disruptions of various kinds – ranging from extreme climate events to supply chain uncertainties and financial volatility – are impacting growth and development. Debt is a serious concern, even as the world falls behind in achieving SDG targets. Technology holds great promise, as well as raising a new host of concerns. How should the members of the SCO respond to these challenges?” he asked.\n",
        "\n",
        "Festive offer\n",
        "“The answers lie in the Charter of our organisation,” he said, adding, “And I urge you to reflect on Article 1 that spells out the goals and tasks of the SCO. Let me summarise it for our collective consideration. The objective is to strengthen mutual trust, friendship and good neighbourliness. It is to develop multi-faceted cooperation, especially of a regional nature. It is to be a positive force in terms of balanced growth, integration and conflict prevention. The Charter was equally clear what the key challenges were. And these were primarily three, that the SCO was committed to combatting: one, terrorism; two, separatism; and three, extremism.”\n",
        "\n",
        "Jaishankar stated that only by reaffirming the commitment to the Charter most sincerely that they can fully realise the benefits of cooperation and integration that it envisages. “This is not just an endeavour for our own benefit. We all realise that the world is moving towards multi-polarity. Globalisation and rebalancing are realities that cannot be denied. Cumulatively, they have created many new opportunities in terms of trade, investment, connectivity, energy flows and other forms of collaboration. There is no question that our region would benefit immensely if we take this forward. Not just that, others too would draw their own inspiration and lessons from such efforts.”\n",
        "\"\"\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are a helpful assistant that specialize in article summarization\n",
        "            your task is to summarize given text article and generate title for it\n",
        "            If the provided article doesnt contain coherent and meaningful content,\n",
        "            just return empty response\"\"\",\n",
        "    },\n",
        "    {\"role\": \"human\", \"content\": text_content},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "lora_output = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hP4cO89OnZs",
        "outputId": "e413fc65-7357-4c8c-85b9-724a343b1e7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article:   Responding to geopolitical challenges \n",
            "Festive offer \n",
            "\n",
            "The SCO (Shanghai Cooperation Organisation) seeks to strengthen trust and friendship among its members.  Jaishankar stated that reaffirming commitment to the SCO’s charter can enable it to achieve the benefits of cooperation and integration it seeks to foster.<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#main code ui"
      ],
      "metadata": {
        "id": "cnqH1gUFRLoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip  -q install streamlit\n",
        "!pip -q install --upgrade requests\n",
        "!pip -q install beautifulsoup4\n",
        "!pip -q install unsloth transformers\n",
        "!pip -q install newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRDnGJiCO7Pp",
        "outputId": "f6f06ab1-75c3-48e3-c434-90a9877497a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cusolver-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import TextStreamer\n",
        "import re\n",
        "import torch\n",
        "\n",
        "# Streamlit app config\n",
        "st.set_page_config(\n",
        "    page_title=\"Article Summarizer\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"collapsed\"\n",
        ")\n",
        "\n",
        "# Session state setup\n",
        "if 'url_input' not in st.session_state:\n",
        "    st.session_state.url_input = \"\"\n",
        "if 'text_input_area' not in st.session_state:\n",
        "    st.session_state.text_input_area = \"\"\n",
        "if 'summary_output_state' not in st.session_state:\n",
        "     st.session_state.summary_output_state = \"\"\n",
        "if 'original_text_state' not in st.session_state:\n",
        "     st.session_state.original_text_state = \"\"\n",
        "if 'input_processed' not in st.session_state:\n",
        "    st.session_state.input_processed = False\n",
        "if 'clear_requested' not in st.session_state:\n",
        "    st.session_state.clear_requested = False\n",
        "if 'max_new_tokens' not in st.session_state:\n",
        "    st.session_state.max_new_tokens = 512 # Default summary length\n",
        "\n",
        "# Handle Clear button action\n",
        "if st.session_state.clear_requested:\n",
        "    st.session_state.url_input = \"\"\n",
        "    st.session_state.text_input_area = \"\"\n",
        "    st.session_state.summary_output_state = \"\"\n",
        "    st.session_state.original_text_state = \"\"\n",
        "    st.session_state.input_processed = False\n",
        "    st.session_state.max_new_tokens = 512 # Reset length\n",
        "    st.session_state.clear_requested = False\n",
        "\n",
        "\n",
        "# Load model with caching\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model_folder_path = '/content/drive/MyDrive/my_trained_model/my_trained_model'\n",
        "    max_seq_length = 2048\n",
        "    dtype = None\n",
        "    load_in_4bit = True\n",
        "\n",
        "    try:\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            model_name=model_folder_path,\n",
        "            max_seq_length=max_seq_length,\n",
        "            dtype=dtype,\n",
        "            load_in_4bit=load_in_4bit,\n",
        "        )\n",
        "        model.eval()\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load model: {e}. Ensure model path is correct and Drive is mounted.\")\n",
        "        st.stop()\n",
        "\n",
        "model, tokenizer = load_model()\n",
        "\n",
        "\n",
        "# Fetch article content from URL\n",
        "def fetch_url(url):\n",
        "    if not url:\n",
        "        return \"Error: No URL provided.\"\n",
        "\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "            'Accept-Language': 'en-US,en;q=0.5',\n",
        "            'Connection': 'keep-alive',\n",
        "            'Upgrade-Insecure-Requests': '1',\n",
        "            'Referer': 'https://www.google.com/'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, headers=headers, timeout=15)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        article_content = soup.find('article')\n",
        "        if not article_content:\n",
        "            common_classes = ['article-body', 'article__content', 'entry-content', 'post-content', 'story-body', 'td-post-content', 'body-content']\n",
        "            for class_name in common_classes:\n",
        "                article_content = soup.find('div', class_=class_name)\n",
        "                if article_content: break\n",
        "\n",
        "        if not article_content:\n",
        "             paragraphs = soup.find_all('p')\n",
        "             raw_text = '\\n\\n'.join([p.get_text() for p in paragraphs])\n",
        "        else:\n",
        "             raw_text = article_content.get_text()\n",
        "\n",
        "        if not raw_text:\n",
        "             raw_text = soup.get_text()\n",
        "\n",
        "        text_content = re.sub(r'\\s+', ' ', raw_text).strip()\n",
        "\n",
        "        if not text_content:\n",
        "             return \"Error: Could not extract text from URL.\"\n",
        "\n",
        "        return text_content\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching URL: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error parsing content: {e}\"\n",
        "\n",
        "\n",
        "def summarize(text_content, tokenizer, model, max_new_tokens_limit):\n",
        "    if not text_content or text_content.startswith(\"Error\"):\n",
        "        return \"Could not summarize.\"\n",
        "\n",
        "    system_content = \"\"\n",
        "    include_title_format = True\n",
        "\n",
        "    if max_new_tokens_limit == 256:\n",
        "        system_content = \"\"\"You are a helpful assistant for article summarization.\n",
        "            Your task is to provide a short summary of the given text article in 2 to 3 sentences. Do not generate a title.\n",
        "            Return empty if content is not meaningful.\n",
        "            \"\"\"\n",
        "        include_title_format = False\n",
        "\n",
        "    elif max_new_tokens_limit == 1024:\n",
        "        system_content = \"\"\"You are a helpful assistant for article summarization.\n",
        "            Your task is to provide a medium-length summary of the given text article, forming a single paragraph containing a minimum of 5 sentences. Ensure you cover all the main topics and distinct points discussed. Generate a title.\n",
        "            Return empty if content is not meaningful.\n",
        "            \"\"\"\n",
        "\n",
        "    else:\n",
        "         system_content = \"\"\"You are a helpful assistant for article summarization.\n",
        "            Your task is to provide a long summary of the given text article in 7 to 8 sentences forming a paragraph, or as 2 small paragraphs (2-3 sentences each). Generate a title.\n",
        "            Return empty if content is not meaningful.\n",
        "            \"\"\"\n",
        "\n",
        "    if include_title_format:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_content + \"\"\"\n",
        "Format:\n",
        "Title: [Generated Title]\n",
        "\n",
        "[Generated Summary]\n",
        "                \"\"\",\n",
        "            },\n",
        "            {\"role\": \"human\", \"content\": text_content},\n",
        "        ]\n",
        "    else:\n",
        "         messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_content,\n",
        "            },\n",
        "            {\"role\": \"human\", \"content\": text_content},\n",
        "        ]\n",
        "\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize = True,\n",
        "        add_generation_prompt = True,\n",
        "        return_tensors = \"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    with st.spinner(f\"Generating summary (max {max_new_tokens_limit} tokens)...\"):\n",
        "        lora_output = model.generate(\n",
        "            input_ids = inputs,\n",
        "            max_new_tokens = max_new_tokens_limit,\n",
        "            use_cache = True,\n",
        "            temperature = 0.7,\n",
        "            min_p = 0.5,\n",
        "            do_sample = True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    newly_generated_tokens = lora_output[0][len(inputs[0]):]\n",
        "    summary = tokenizer.decode(newly_generated_tokens, skip_special_tokens=True)\n",
        "    summary = summary.strip()\n",
        "\n",
        "\n",
        "    if not include_title_format and summary.lower().startswith(\"title:\"):\n",
        "         match = re.search(r'(?i)Title:\\s*.*?\\n\\n(.*)', summary, re.DOTALL)\n",
        "         if match:\n",
        "              summary = match.group(1).strip()\n",
        "         else:\n",
        "             lines = summary.split('\\n', 1)\n",
        "             if len(lines) > 1 and lines[0].lower().startswith(\"title:\"):\n",
        "                 summary = lines[1].strip()\n",
        "\n",
        "\n",
        "    if not summary:\n",
        "        return \"Summary could not be generated by model.\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# --- Streamlit App Layout ---\n",
        "st.title(\"📰 AI Article Summarizer\")\n",
        "st.markdown(\"\"\"\n",
        "    Summarize articles from a URL or provided text. Choose the summary length.\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"Input\")\n",
        "    input_type = st.radio(\"Choose input type:\", (\"URL\", \"Text\"), key=\"input_type_radio\")\n",
        "\n",
        "# Summary length selection\n",
        "    summary_length_option = st.selectbox(\n",
        "        \"Select summary length:\",\n",
        "        options=[\"Short (approx. 256 tokens)\", \"Medium (approx. 512 tokens)\", \"Long (approx. 1024 tokens)\"],\n",
        "        index=1,\n",
        "        key=\"summary_length_selectbox\"\n",
        "    )\n",
        "\n",
        "    # Map option to tokens\n",
        "    if summary_length_option == \"Short (approx. 256 tokens)\":\n",
        "        st.session_state.max_new_tokens = 256\n",
        "    elif summary_length_option == \"Medium (approx. 512 tokens)\":\n",
        "        st.session_state.max_new_tokens = 512\n",
        "    elif summary_length_option == \"Long (approx. 1024 tokens)\":\n",
        "        st.session_state.max_new_tokens = 1024\n",
        "\n",
        "    if input_type == \"URL\":\n",
        "        url = st.text_input(\"Enter URL:\", key=\"url_input\")\n",
        "        process_button = st.button(\"Summarize URL\", key=\"summarize_url_button\")\n",
        "    else:\n",
        "        text_content_input = st.text_area(\"Paste text here:\", height=350, key=\"text_input_area\")\n",
        "        process_button = st.button(\"Summarize Text\", key=\"summarize_text_button\")\n",
        "\n",
        "    if st.button(\"Clear All\", key=\"clear_button\"):\n",
        "        st.session_state.clear_requested = True\n",
        "        st.rerun()\n",
        "\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"Output\")\n",
        "    summary_placeholder = st.empty()\n",
        "    original_text_placeholder = st.empty()\n",
        "\n",
        "\n",
        "# --- Processing Logic ---\n",
        "if process_button and ( (input_type == \"URL\" and (st.session_state.url_input and st.session_state.url_input.strip())) or (input_type == \"Text\" and st.session_state.text_input_area and st.session_state.text_input_area.strip()) ):\n",
        "    st.session_state.input_processed = True\n",
        "    st.session_state.summary_output_state = \"\"\n",
        "    st.session_state.original_text_state = \"\"\n",
        "\n",
        "    current_input = st.session_state.url_input if input_type == \"URL\" else st.session_state.text_input_area\n",
        "    selected_max_new_tokens = st.session_state.max_new_tokens\n",
        "\n",
        "    if input_type == \"URL\":\n",
        "        with st.spinner(\"Fetching article content...\"):\n",
        "            text_content = fetch_url(current_input)\n",
        "\n",
        "        if text_content.startswith(\"Error\"):\n",
        "            st.session_state.summary_output_state = text_content\n",
        "            st.session_state.original_text_state = \"\"\n",
        "        else:\n",
        "            st.session_state.original_text_state = text_content\n",
        "            summary = summarize(text_content, tokenizer, model, selected_max_new_tokens)\n",
        "            st.session_state.summary_output_state = summary\n",
        "\n",
        "    else:\n",
        "        text_content = current_input.strip()\n",
        "        if not text_content:\n",
        "             st.session_state.summary_output_state = \"Please enter some text.\"\n",
        "             st.session_state.original_text_state = \"\"\n",
        "        else:\n",
        "            st.session_state.original_text_state = text_content\n",
        "            summary = summarize(text_content, tokenizer, model, selected_max_new_tokens)\n",
        "            st.session_state.summary_output_state = summary\n",
        "\n",
        "    st.rerun()\n",
        "\n",
        "\n",
        "# --- Display Results ---\n",
        "if st.session_state.input_processed:\n",
        "    if st.session_state.original_text_state and not (st.session_state.original_text_state.startswith(\"Error\") or st.session_state.original_text_state.startswith(\"Could not\")):\n",
        "        original_text_placeholder.subheader(\"Original Text Preview:\")\n",
        "        with original_text_placeholder.expander(\"View original text\"):\n",
        "            word_count = len(st.session_state.original_text_state.split())\n",
        "            char_count = len(st.session_state.original_text_state)\n",
        "            st.info(f\"Words: {word_count} | Chars: {char_count}\")\n",
        "            st.text_area(\"Full Text\", st.session_state.original_text_state, height=300, key=\"displayed_original_text\", disabled=True)\n",
        "\n",
        "\n",
        "    if st.session_state.summary_output_state:\n",
        "        if st.session_state.summary_output_state.startswith(\"Error\") or st.session_state.summary_output_state.startswith(\"Could not\"):\n",
        "            summary_placeholder.error(st.session_state.summary_output_state)\n",
        "            if st.session_state.original_text_state and not (st.session_state.original_text_state.startswith(\"Error\") or st.session_state.original_text_state.startswith(\"Could not\")):\n",
        "                 summary_placeholder.write(\"Summary could not be generated based on extracted text.\")\n",
        "        else:\n",
        "            summary_placeholder.subheader(\"Summary:\")\n",
        "            summary_placeholder.write(st.session_state.summary_output_state)\n",
        "\n",
        "    elif st.session_state.original_text_state and not st.session_state.summary_output_state:\n",
        "         summary_placeholder.subheader(\"Summary:\")\n",
        "         summary_placeholder.write(\"Summary not generated (model output empty).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1zeFvx0S79K",
        "outputId": "897e0fa4-a6f0-4ad4-bdb9-98c869d7dd17"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8zybtLRPBUc",
        "outputId": "52b467cd-3ec5-4534-9a91-e9e249ca6ecf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.110.161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK-KIihqPFpS",
        "outputId": "709a39d2-9521-401f-8bd1-7cbff1e038b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.110.161:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://curvy-snails-rescue.loca.lt\n",
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-05-20 07:23:18.020644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747725798.044434    8598 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747725798.051809    8598 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.5.6: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth 2025.5.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
            "2025-05-20 07:23:44.793 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "2025-05-20 07:24:02.246 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbi_yAohRJj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}